{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49b6adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "301b2e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([\n",
    "    [0,1,1],\n",
    "    [0,0,1],\n",
    "    [0,0,0],\n",
    "    [1,1,0]\n",
    "])\n",
    "Y_train = ['Y', 'N', 'Y', 'Y']\n",
    "X_test = np.array([[1,1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "136660de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_indices(labels):\n",
    "    \"\"\"\n",
    "    Group samples based on their labels and return indices\n",
    "    @param label: list of labels\n",
    "    @return: dict, {class1: [indices], class2: [indices]}\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "    label_indices = defaultdict(list)\n",
    "    for index, label in enumerate(labels):\n",
    "        label_indices[label].append(index)\n",
    "    return label_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81e4598f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {'Y': [0, 2, 3], 'N': [1]})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_indices = get_label_indices(Y_train)\n",
    "label_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02b684ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prior(label_indices):\n",
    "    \"\"\"\n",
    "    Compute prior based on training samples\n",
    "     @param label_indices: grouped sample indices by class\n",
    "     @return: dictionary, with class label as key, corresponding\n",
    "     prior as the value\n",
    "    \"\"\"\n",
    "    prior = {label: len(indices) for label, indices in label_indices.items()}\n",
    "    total_count = sum(prior.values())\n",
    "    for label in prior:\n",
    "        prior[label] /= total_count\n",
    "    return prior\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e3e7fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Y': 0.75, 'N': 0.25}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior = get_prior(label_indices)\n",
    "prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e398ba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_likelihood(features, label_indices, smoothing=0):\n",
    "    \"\"\"\n",
    "    Compute likelihood based on training samples\n",
    "    @param features: matrix of features\n",
    "    @param label_indices: grouped sample indices by class\n",
    "    @param smoothing: integer, additive smoothing parameter\n",
    "    @return: dictionary, with class as key, corresponding\n",
    "    conditional probability P(feature|class) vector\n",
    "    as value\n",
    "    \"\"\"\n",
    "    likelihood = {}\n",
    "    for label, indices in label_indices.items():\n",
    "        likelihood[label] = features[indices, :].sum(axis=0) + smoothing\n",
    "        total_count = len(indices)\n",
    "        likelihood[label] = likelihood[label] / (total_count + 2 * smoothing)\n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c0ada2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Y': array([0.4, 0.6, 0.4]), 'N': array([0.33333333, 0.33333333, 0.66666667])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothing = 1\n",
    "likelihood = get_likelihood(X_train, label_indices, smoothing)\n",
    "likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbf4ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posterior(X, prior, likelihood):\n",
    "    \"\"\"\n",
    "    Compute posterior of testing samples, based on prior and\n",
    "    likelihood\n",
    "    @param X: testing samples\n",
    "    @param prior: dictionary, with class label as key,\n",
    "    corresponding prior as the value\n",
    "    @param likelihood: dictionary, with class label as key,\n",
    "    corresponding conditional probability\n",
    "    vector as value\n",
    "    @return: dictionary, with class label as key, corresponding\n",
    "    posterior as value\n",
    "    \"\"\"\n",
    "    posteriors = []\n",
    "    for x in X:\n",
    "        #posterior is proportional to prior * likelihood\n",
    "        posterior = prior.copy()\n",
    "        for label, likelihood_label in likelihood.items():\n",
    "            for index, bool_value in enumerate(x):\n",
    "                posterior[label] *= likelihood_label[index] if bool_value else (1 - likelihood_label[index])\n",
    "        #normalize so that all sums up to 1\n",
    "        sum_posterior = sum(posterior.values())\n",
    "        for label in posterior:\n",
    "            if posterior[label] == float('inf'):\n",
    "                posterior[label] = 1.0\n",
    "            else:\n",
    "                posterior[label] /= sum_posterior\n",
    "        posteriors.append(posterior.copy())\n",
    "    return posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87377181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Y': 0.9210360075805433, 'N': 0.07896399241945673}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior = get_posterior(X_test, prior, likelihood)\n",
    "posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d00410c",
   "metadata": {},
   "source": [
    "## Implementing Naive Bayes with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b4913c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ebd0fe41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = BernoulliNB(alpha=1.0, fit_prior=True)\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a55d3ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07896399, 0.92103601]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob = clf.predict_proba(X_test)\n",
    "pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "510837f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Y'], dtype='<U1')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = clf.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76100e72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
